{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习第三次实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解并描述BP算法原理\n",
    "\n",
    "BP算法，即反向传播算法（Backpropagation），是一种用于训练人工神经网络的广泛应用的学习算法。其核心目的是通过网络中**权重的优化来最小化损失函数**，使模型的预测值尽可能接近真实值。\n",
    "\n",
    "其基本原理：\n",
    "\n",
    "1. **前向传播**：输入数据在神经网络中从输入层向隐藏层再到输出层传播。每一层的神经元接收到上一层的输出，通过加权和并应用激活函数处理生成本层的输出。\n",
    "\n",
    "2. **计算损失**：在输出层，根据网络的输出和实际的目标值（标签）计算损失。\n",
    "\n",
    "3. **反向传播**：算法核心，其目标是**计算损失函数关于网络中每个权重的梯度**。这个过程从输出层开始，逆向经过每一层，直到达到输入层。梯度表示损失函数增加最快的方向，因此，通过调整权重与梯度方向相反，可以使损失减小。对于每一层，梯度是通过**链式法则**来计算的。\n",
    "\n",
    "4. **权重更新**：一旦计算得到梯度，就使用这些梯度来更新网络中的权重。这通常通过梯度下降或其他优化算法（如Adam、RMSprop等）来完成。更新公式大致为：$ W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W} $，其中 $ \\eta $ 是学习率，$ L $ 是损失函数，$ W $ 是待更新的权重。\n",
    "\n",
    "5. **迭代优化**：重复执行上述步骤（前向传播、计算损失、反向传播、更新权重）直到模型性能达到满意的程度或达到一定的迭代次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP算法设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 激活函数及其导数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# 初始化参数\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    params = {\n",
    "        \"W1\": np.random.randn(hidden_size, input_size) * 0.1,\n",
    "        \"b1\": np.zeros((hidden_size, 1)),\n",
    "        \"W2\": np.random.randn(output_size, hidden_size) * 0.1,\n",
    "        \"b2\": np.zeros((output_size, 1))\n",
    "    }\n",
    "    return params\n",
    "\n",
    "# 前向传播\n",
    "def forward_propagation(X, params):\n",
    "    Z1 = np.dot(params[\"W1\"], X) + params[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(params[\"W2\"], A1) + params[\"b2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
    "    return A2, cache\n",
    "\n",
    "# 计算损失\n",
    "def compute_loss(Y, A2):\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2)) / m\n",
    "    return cost\n",
    "\n",
    "# 反向传播\n",
    "def backward_propagation(params, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "    dZ2 = cache[\"A2\"] - Y\n",
    "    dW2 = np.dot(dZ2, cache[\"A1\"].T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "    dA1 = np.dot(params[\"W2\"].T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid_derivative(cache[\"A1\"])\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return grads\n",
    "\n",
    "# 更新参数\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "    params[\"W1\"] -= learning_rate * grads[\"dW1\"]\n",
    "    params[\"b1\"] -= learning_rate * grads[\"db1\"]\n",
    "    params[\"W2\"] -= learning_rate * grads[\"dW2\"]\n",
    "    params[\"b2\"] -= learning_rate * grads[\"db2\"]\n",
    "    return params\n",
    "\n",
    "# 模型训练\n",
    "def model(X, Y, hidden_size, learning_rate, num_iterations):\n",
    "    input_size = X.shape[0]\n",
    "    output_size = Y.shape[0]\n",
    "    params = initialize_parameters(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, params)\n",
    "        cost = compute_loss(Y, A2)\n",
    "        grads = backward_propagation(params, cache, X, Y)\n",
    "        params = update_parameters(params, grads, learning_rate)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost:.4f}\")\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集获取\n",
    "\n",
    "1. 鸢尾花数据集（Iris）：包含150个样本，分为3个类别，每个类别50个样本。每个样本有4个特征，分别是花瓣和花萼的长度和宽度。\n",
    "2. 葡萄酒数据集（Wine）：包含178个样本，分为3个类别，代表了三种不同的意大利葡萄酒。有13个特征，这些特征是从葡萄酒的化学成分分析中得出的，比如酒精度、苹果酸含量等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践，将算法应用于获取的分类数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先应用于鸢尾花数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "iris = pd.read_csv(\"data/iris.csv\")\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 1.0747 - accuracy: 0.3238\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7619\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8286\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8952\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.9143\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9429\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9333\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9429\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9524\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9524\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9619\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9714\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9524\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9619\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9714\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9714\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9619\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9619\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9714\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9524\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9619\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9619\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9810\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9619\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9524\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9619\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9714\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9714\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9619\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9619\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9619\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9714\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9619\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9810\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9619\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9810\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9810\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9810\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9810\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9619\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9810\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9524\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9714\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9619\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9810\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9810\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9810\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9810\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9810\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9619\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 867us/step - loss: 0.0595 - accuracy: 0.9810\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9810\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9810\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9810\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9714\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9810\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9810\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9810\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9810\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9810\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9810\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9810\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9810\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9810\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9810\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9810\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9810\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9810\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9810\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9619\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9810\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9810\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9810\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9714\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9810\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9810\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9810\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Loss: 0.0177, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, -1].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, activation='relu', input_shape=(4,)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "通过数据预处理与模型训练，我构建了一个具有一个隐藏层的简单神经网络并使用`Adam`优化算法，将其应用到鸢尾花数据集上，效果显著。\n",
    "\n",
    "算法在该数据集上的预测准确度为 $100\\%$，损失函数的值为 $0.0177$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 然后应用于葡萄酒数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  target  \n",
      "0                          3.92   1065.0       0  \n",
      "1                          3.40   1050.0       0  \n",
      "2                          3.17   1185.0       0  \n",
      "3                          3.45   1480.0       0  \n",
      "4                          2.93    735.0       0  \n"
     ]
    }
   ],
   "source": [
    "wine = pd.read_csv(\"data/wine.csv\")\n",
    "print(wine.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 0.8097 - accuracy: 0.6532\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.9194\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9839\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9919\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9919\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9919\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5887e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1138e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 842us/step - loss: 8.7488e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 993us/step - loss: 8.5499e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 978us/step - loss: 8.2541e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0699e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 7.7400e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5171e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.3359e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1120e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9618e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7475e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5646e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.4253e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.2106e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0715e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.9131e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8030e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.6445e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5151e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3653e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2381e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1168e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.9832e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8762e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7607e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6422e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5583e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4367e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3492e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2683e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1619e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0325e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9624e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8744e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7902e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6779e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5797e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4961e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4549e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3714e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2703e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1613e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.1158e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0675e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0006e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9425e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8841e-04 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9815\n",
      "Loss: 0.0280, Accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "X = wine.iloc[:, :-1].values\n",
    "y = wine.iloc[:, -1].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(20, activation='relu', input_shape=(13,)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "同样的模型训练步骤，将其应用到葡萄酒数据集上，效果依旧显著。\n",
    "\n",
    "算法在该数据集上的预测准确度为 $98.15\\%$，损失函数的值为 $0.0280$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
